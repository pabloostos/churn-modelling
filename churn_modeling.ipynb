{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________________________________________________________________________________________________________________________________________\n",
    "# **ASSIGNMENT 02 - CLASSIFICATION EXERCISE**\n",
    "__________________________________________________________________________________________________________________________________________________\n",
    "- Due Date: November 15th 2022\n",
    "- Course: Data Analytics for Decision Making\n",
    "- Master: MCSBT\n",
    "- Professor: Jesús García San Luis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **INTRODUCTION**\n",
    "________________________________________________________________________________________________________________________________________________\n",
    "A great number of the tasks that are carried out as part of operation and business processes focus on the organisation and classification of data to facilitate its management or automazation. The goal of this assignment is the prediction of whether a customer will leave a company or not, we will do this through classification techniques adter preparing the data, like we did in the first assignment. \n",
    "\n",
    "Additionaly, in this assignment we will build a prediction model that will perform a classification of the customers of a company, whther they will leave of not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________________________________________________________________________________________________________________________________________\n",
    "### **FIRST STEPS** -> importing libraries we will be using and loading the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "d = pd.read_csv('churn_modeling.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________________________________________________________________________________________________________________________________________\n",
    "## **DATA ANALYSIS**\n",
    "In this section of the assignment we will go through the dataframe, analysing the most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          2       0.00              1          1               1   \n",
       "1          1   83807.86              1          0               1   \n",
       "2          8  159660.80              3          1               0   \n",
       "3          1       0.00              2          0               0   \n",
       "4          2  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995       5       0.00              2          1               0   \n",
       "9996      10   57369.61              1          1               1   \n",
       "9997       7       0.00              1          0               1   \n",
       "9998       3   75075.31              2          1               0   \n",
       "9999       4  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the whole dataset to see its shape, attributes, features and columns.\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RowNumber</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>5.000500e+03</td>\n",
       "      <td>2886.895680</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2500.75</td>\n",
       "      <td>5.000500e+03</td>\n",
       "      <td>7.500250e+03</td>\n",
       "      <td>10000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CustomerId</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>71936.186123</td>\n",
       "      <td>15565701.00</td>\n",
       "      <td>15628528.25</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>15815690.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CreditScore</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>6.505288e+02</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>350.00</td>\n",
       "      <td>584.00</td>\n",
       "      <td>6.520000e+02</td>\n",
       "      <td>7.180000e+02</td>\n",
       "      <td>850.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>3.892180e+01</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>18.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>3.700000e+01</td>\n",
       "      <td>4.400000e+01</td>\n",
       "      <td>92.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tenure</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>5.012800e+00</td>\n",
       "      <td>2.892174</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balance</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>7.648589e+04</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.719854e+04</td>\n",
       "      <td>1.276442e+05</td>\n",
       "      <td>250898.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumOfProducts</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.530200e+00</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HasCrCard</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>7.055000e-01</td>\n",
       "      <td>0.455840</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IsActiveMember</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>5.151000e-01</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.000902e+05</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>11.58</td>\n",
       "      <td>51002.11</td>\n",
       "      <td>1.001939e+05</td>\n",
       "      <td>1.493882e+05</td>\n",
       "      <td>199992.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exited</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>2.037000e-01</td>\n",
       "      <td>0.402769</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count          mean           std          min  \\\n",
       "RowNumber        10000.0  5.000500e+03   2886.895680         1.00   \n",
       "CustomerId       10000.0  1.569094e+07  71936.186123  15565701.00   \n",
       "CreditScore      10000.0  6.505288e+02     96.653299       350.00   \n",
       "Age              10000.0  3.892180e+01     10.487806        18.00   \n",
       "Tenure           10000.0  5.012800e+00      2.892174         0.00   \n",
       "Balance          10000.0  7.648589e+04  62397.405202         0.00   \n",
       "NumOfProducts    10000.0  1.530200e+00      0.581654         1.00   \n",
       "HasCrCard        10000.0  7.055000e-01      0.455840         0.00   \n",
       "IsActiveMember   10000.0  5.151000e-01      0.499797         0.00   \n",
       "EstimatedSalary  10000.0  1.000902e+05  57510.492818        11.58   \n",
       "Exited           10000.0  2.037000e-01      0.402769         0.00   \n",
       "\n",
       "                         25%           50%           75%          max  \n",
       "RowNumber            2500.75  5.000500e+03  7.500250e+03     10000.00  \n",
       "CustomerId       15628528.25  1.569074e+07  1.575323e+07  15815690.00  \n",
       "CreditScore           584.00  6.520000e+02  7.180000e+02       850.00  \n",
       "Age                    32.00  3.700000e+01  4.400000e+01        92.00  \n",
       "Tenure                  3.00  5.000000e+00  7.000000e+00        10.00  \n",
       "Balance                 0.00  9.719854e+04  1.276442e+05    250898.09  \n",
       "NumOfProducts           1.00  1.000000e+00  2.000000e+00         4.00  \n",
       "HasCrCard               0.00  1.000000e+00  1.000000e+00         1.00  \n",
       "IsActiveMember          0.00  1.000000e+00  1.000000e+00         1.00  \n",
       "EstimatedSalary     51002.11  1.001939e+05  1.493882e+05    199992.48  \n",
       "Exited                  0.00  0.000000e+00  0.000000e+00         1.00  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some things to highlight from this table are the customer ages go from 18 to 92 years old with the median around 40. Another interesting thing to look at is the TENURE (permanencia) with a mean of around 5 years and most of customer's tenure are above 3 years, showing high level of loyalty. \n",
    "Customers are pretty wealthy we could say, being the estimated salary above 51000 for the majority. \n",
    "Probably the most important feature to look at is out target variable: **EXITED**. This feature allows us to calculate the churn rate of the customers.\n",
    "\n",
    "Now, we will look more in detail at the different feature, especially those that I believe to be more relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_churned = d[d['Exited'] == 1]\n",
    "d_retained = d[d['Exited'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Age**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Age', ylabel='count'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Age', hue = 'Exited', data = d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking closely at the age column, we have to highlight that the older the customer, the more likely he will be to leave the company. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. CreditScore**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='CreditScore', ylabel='count'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='CreditScore', hue = 'Exited', data = d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This column does not tell us much about the likelyhood of leaving the company, the distribution of data is pretty much the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________________________________________________________________________________________________________________________________________\n",
    "## **DATA PREPARATION**\n",
    "*This part of the assignment consists on the act of cleaning and consolidating the raw data before submitting it to analysis. Carrying out the process of validating, cleaning and augmenting the raw data is the foundation to obtain precise and significant insights from them. \n",
    "In this assignment we will recall some of the data preparation techniques seen in the first assignment and session 4 of the course.* \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In the previous chunk of code we can already see its shape, but to see it more clearly: \n",
    "d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*From the last commands, we can see that the dataset has 10000 rows and 14 columns. Now we will see more in depth what these rows and columns contain and make a cleans so that the data can be analysed.*\n",
    "\n",
    "- First we will look inside all rows to see if there are null values, if there are any, we will impute them. Null or missing values can be described as those values that are not stored for some variables, these values can reduce the accuracy of our model and bias it, they are often represented as NaN. \n",
    "\n",
    "- Then we will look at each of the colums, analysing and understanding its features. After examining the columns one of the most usual operations is narrowing down the columns. This can be effectuated because the columns or features do not provide significant information for the model to meke a good prediction. \n",
    "\n",
    "- We will perform encodings on the categorical columns that require it. Categorical values are those that can only take a fixed, limited amount of values. We can perform different types of encoding such as replacing values or one hot encoding and see the effect they have on the accuracy. \n",
    "\n",
    "- We also have to address class imbalance. A balanced dataset is one in which the same number of input samples are used to represent each output class (or target class), in this class the \"Exited\" feature.\n",
    "\n",
    "- Lastly, Scaling (or standardising) the data is another major aspect when we are talking about predictions. The standardisation is a data preparation procedure that is executed with the aim of rescaling the columns so that the mean and standard deviation are 0 and 1 respectively. ***DISCLAIMER: I will first do a first run at the exercise without doing the standarization, after this first case I will try standardising the data and compare the results***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. SEARCHING FOR NULL VALUES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int64  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "d.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          0\n",
       "CustomerId         0\n",
       "Surname            0\n",
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SEARCHING FOR NULL VALUES. These commands will look for the number of missing values in each column\n",
    "d.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the dataset is free of missing values, this is an unusual case. Either way, by implementing the imputer code shown below, it would impute the missing values with the *sklearn.impute* library and clean the data from missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "imputer = IterativeImputer()\n",
    "imputed = imputer.fit_transform(d)\n",
    "df_imputed = pd.DataFrame(imputed, columns=d.columns)\n",
    "\n",
    "df_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. NARROWING COLUMNS**\n",
    "First of all, we can look at the amount of unique values in each of the features (columns). This gives us a broad idea of how the data is distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          10000\n",
       "CustomerId         10000\n",
       "Surname             2932\n",
       "CreditScore          460\n",
       "Geography              3\n",
       "Gender                 2\n",
       "Age                   70\n",
       "Tenure                11\n",
       "Balance             6382\n",
       "NumOfProducts          4\n",
       "HasCrCard              2\n",
       "IsActiveMember         2\n",
       "EstimatedSalary     9999\n",
       "Exited                 2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> As we can see, the first observation we can make by looking at the results is that the first two features are specific for each of the customers. This way, we determine that we can get rid of the first two columns. Another column we can get rid of is the Surname column, as we can see there are 2932 unique values for this column, nevertheless, it is specific to each customer so we come to the conclusion that we can forget about this column even if they are repeated. \n",
    "\n",
    "**Narrowing down the data frame: columns RowNumber, CustomerID and Surname**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             619    France  Female   42       2       0.00              1   \n",
       "1             608     Spain  Female   41       1   83807.86              1   \n",
       "2             502    France  Female   42       8  159660.80              3   \n",
       "3             699    France  Female   39       1       0.00              2   \n",
       "4             850     Spain  Female   43       2  125510.82              1   \n",
       "...           ...       ...     ...  ...     ...        ...            ...   \n",
       "9995          771    France    Male   39       5       0.00              2   \n",
       "9996          516    France    Male   35      10   57369.61              1   \n",
       "9997          709    France  Female   36       7       0.00              1   \n",
       "9998          772   Germany    Male   42       3   75075.31              2   \n",
       "9999          792    France  Female   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0             1               1        101348.88       1  \n",
       "1             0               1        112542.58       0  \n",
       "2             1               0        113931.57       1  \n",
       "3             0               0         93826.63       0  \n",
       "4             1               1         79084.10       0  \n",
       "...         ...             ...              ...     ...  \n",
       "9995          1               0         96270.64       0  \n",
       "9996          1               1        101699.77       0  \n",
       "9997          0               1         42085.58       1  \n",
       "9998          1               0         92888.52       1  \n",
       "9999          1               0         38190.78       0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = d.drop(columns = [\"RowNumber\", \"CustomerId\", \"Surname\"])\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we end up with 11 relevant columns to analyse. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. ENCODING**\n",
    "We will perform encodings on the variables that require it, these are those features that can only take a fixed, limited amount of values. There are different ways to perform encodings, I have opted to do an arbitrary encoding of those variables that require it, nevertheless if I have time I will perform a one hot encoding and compare the results between the two encodings. \n",
    "\n",
    "Firstly we will have a look at the categorical features we find in our data frame, and thanks to the d.nunique() chunk of code we see that the columns with few unique values are: Geography, Gender, Tenure, NumOfProducts, HasCrCard, IsActiveMember and Exited, but we already know that Exited is 0 if they have exited and 1 if they are loyal. \n",
    "\n",
    "Now, from the d.info() chunk of code, we can see the data type of each feature (Dtype), and we come to the conslusion that the only columns we have to encode are Geography and Gender (the only OBJECT types we find = strings), the rest are integers so we can assume they are already \"encoded\". -> We have to encode those OBJECT types so that the learner is able to analyse the data since it can only read numerical values. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['France', 'Spain', 'Germany'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['Geography'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Female', 'Male'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['Gender'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.1. Geography**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Geography', ylabel='count'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Geography', data = d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to note that customers come from 3 different countries (Fannce, Spain and Germany), with the most number of residents in France.\n",
    "\n",
    "**Now we encode the Geography column -> France = 1 ; Spain = 2 ; Germany = 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             619          1  Female   42       2       0.00              1   \n",
       "1             608          2  Female   41       1   83807.86              1   \n",
       "2             502          1  Female   42       8  159660.80              3   \n",
       "3             699          1  Female   39       1       0.00              2   \n",
       "4             850          2  Female   43       2  125510.82              1   \n",
       "...           ...        ...     ...  ...     ...        ...            ...   \n",
       "9995          771          1    Male   39       5       0.00              2   \n",
       "9996          516          1    Male   35      10   57369.61              1   \n",
       "9997          709          1  Female   36       7       0.00              1   \n",
       "9998          772          3    Male   42       3   75075.31              2   \n",
       "9999          792          1  Female   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0             1               1        101348.88       1  \n",
       "1             0               1        112542.58       0  \n",
       "2             1               0        113931.57       1  \n",
       "3             0               0         93826.63       0  \n",
       "4             1               1         79084.10       0  \n",
       "...         ...             ...              ...     ...  \n",
       "9995          1               0         96270.64       0  \n",
       "9996          1               1        101699.77       0  \n",
       "9997          0               1         42085.58       1  \n",
       "9998          1               0         92888.52       1  \n",
       "9999          1               0         38190.78       0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode_type(x):\n",
    "    if x == 'France':\n",
    "        return 1\n",
    "    if x == 'Spain':\n",
    "        return 2\n",
    "    if x == 'Germany':\n",
    "        return 3\n",
    "\n",
    "d['Geography'] = d['Geography'].transform(encode_type)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.2. Gender**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Gender', ylabel='count'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Gender', data = d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only thing we can highlight from this histogram is that there are more males than females. \n",
    "\n",
    "**Now we encode the Gender feature -> Male = 1 ; Female = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             619          1       0   42       2       0.00              1   \n",
       "1             608          2       0   41       1   83807.86              1   \n",
       "2             502          1       0   42       8  159660.80              3   \n",
       "3             699          1       0   39       1       0.00              2   \n",
       "4             850          2       0   43       2  125510.82              1   \n",
       "...           ...        ...     ...  ...     ...        ...            ...   \n",
       "9995          771          1       1   39       5       0.00              2   \n",
       "9996          516          1       1   35      10   57369.61              1   \n",
       "9997          709          1       0   36       7       0.00              1   \n",
       "9998          772          3       1   42       3   75075.31              2   \n",
       "9999          792          1       0   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0             1               1        101348.88       1  \n",
       "1             0               1        112542.58       0  \n",
       "2             1               0        113931.57       1  \n",
       "3             0               0         93826.63       0  \n",
       "4             1               1         79084.10       0  \n",
       "...         ...             ...              ...     ...  \n",
       "9995          1               0         96270.64       0  \n",
       "9996          1               1        101699.77       0  \n",
       "9997          0               1         42085.58       1  \n",
       "9998          1               0         92888.52       1  \n",
       "9999          1               0         38190.78       0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode_type(x):\n",
    "    if x == 'Female':\n",
    "        return 0\n",
    "    if x == 'Male':\n",
    "        return 1\n",
    "\n",
    "\n",
    "d['Gender'] = d['Gender'].transform(encode_type)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. EXITED CLASS IMBALANCE**\n",
    "We will be looking at the exited class and try to balance the data set so that the learner can take an almost equal amount of observations, the major justification for this is to give each class equal priority. \n",
    "\n",
    "Data balancing is important when predicting variables with low probability of taking place.\n",
    "\n",
    "**First we check how balanced the data frame is:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2037\n",
      "7963\n"
     ]
    }
   ],
   "source": [
    "# Check how balanced is the dataset\n",
    "d_churned = d[d['Exited'] == 1]\n",
    "d_retained = d[d['Exited'] == 0]\n",
    "\n",
    "print(len(d_churned))\n",
    "print(len(d_retained))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the number of people that are loyal customers is much higher than the people that have exited. So we conclude the data frame is imbalanced. \n",
    "\n",
    "**Now we proceed and balance the data frame**\n",
    "We do this so that the number of input samples are used to represent each of the output class (in this case Exited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2037\n",
      "2037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qb/krnv1mhn7h7b_hnb5z9d1dgw0000gn/T/ipykernel_97416/1953443837.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bln = d_churned.append(d_retained_bis)\n"
     ]
    }
   ],
   "source": [
    "# The dataset is unbalanced. \n",
    "# With this code we will undersample the dataset and get balanced classes\n",
    "\n",
    "# index property contains the indexes of the d_retained dataset\n",
    "d_retained_indexes = d_retained.index\n",
    "\n",
    "# get as many fraud indexes (randomly) as non fraud occurrences\n",
    "np.random.seed(42)\n",
    "random_d_retained_indexes = np.random.choice(d_retained_indexes, len(d_churned))\n",
    "\n",
    "# Keep those entries in d_retained\n",
    "d_retained_bis = d.loc[random_d_retained_indexes]\n",
    "\n",
    "# We will form the balanced dataset concatenating d_retained and d_churned\n",
    "bln = d_churned.append(d_retained_bis)\n",
    "\n",
    "# Check the result\n",
    "print(len(bln[bln.Exited == 1]))\n",
    "print(len(bln[bln.Exited == 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a **BALANCED** data frame ('bln'), by undersampling the data frame we got 2037 input samples to represent each of the output class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. STANDARDISATION**\n",
    "\n",
    "This process is done with the aim of normalising the range of the features in the data. We will standardise or normalise the data by substracting the mean and diving by the standard deviation: \n",
    "\n",
    "*(d[column] - d[column].mean()) / d[column].std()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.326205</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.293503</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.225786</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021885</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.440014</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.198154</td>\n",
       "      <td>1</td>\n",
       "      <td>0.117344</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216523</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.536717</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.293503</td>\n",
       "      <td>8</td>\n",
       "      <td>1.332987</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.240675</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.501496</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007456</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.225786</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.108912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.063781</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.388852</td>\n",
       "      <td>2</td>\n",
       "      <td>0.785689</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.365258</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.246426</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007456</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.225786</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.066416</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>-1.391870</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.373939</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.306363</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027987</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.604958</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.278590</td>\n",
       "      <td>7</td>\n",
       "      <td>-1.225786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.008593</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1.256772</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.293503</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.022606</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.125224</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.463698</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.041381</td>\n",
       "      <td>4</td>\n",
       "      <td>0.859922</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.076316</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Geography  Gender       Age  Tenure   Balance  \\\n",
       "0       -0.326205          1       0  0.293503       2 -1.225786   \n",
       "1       -0.440014          2       0  0.198154       1  0.117344   \n",
       "2       -1.536717          1       0  0.293503       8  1.332987   \n",
       "3        0.501496          1       0  0.007456       1 -1.225786   \n",
       "4        2.063781          2       0  0.388852       2  0.785689   \n",
       "...           ...        ...     ...       ...     ...       ...   \n",
       "9995     1.246426          1       1  0.007456       5 -1.225786   \n",
       "9996    -1.391870          1       1 -0.373939      10 -0.306363   \n",
       "9997     0.604958          1       0 -0.278590       7 -1.225786   \n",
       "9998     1.256772          3       1  0.293503       3 -0.022606   \n",
       "9999     1.463698          1       0 -1.041381       4  0.859922   \n",
       "\n",
       "      NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0                 1          1               1         0.021885       1  \n",
       "1                 1          0               1         0.216523       0  \n",
       "2                 3          1               0         0.240675       1  \n",
       "3                 2          0               0        -0.108912       0  \n",
       "4                 1          1               1        -0.365258       0  \n",
       "...             ...        ...             ...              ...     ...  \n",
       "9995              2          1               0        -0.066416       0  \n",
       "9996              1          1               1         0.027987       0  \n",
       "9997              1          0               1        -1.008593       1  \n",
       "9998              2          1               0        -0.125224       1  \n",
       "9999              1          1               0        -1.076316       0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_standard = d\n",
    "for column in ['CreditScore', 'Age', 'Balance','EstimatedSalary']:\n",
    "    d_standard[column] = (d_standard[column] - d_standard[column].mean()) / d_standard[column].std()\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DISCLAIMER: I will also balance the standardised data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2037\n",
      "7963\n"
     ]
    }
   ],
   "source": [
    "# Check how balanced is the dataset\n",
    "d_standard_churned = d_standard[d_standard['Exited'] == 1]\n",
    "d_standard_retained = d_standard[d_standard['Exited'] == 0]\n",
    "\n",
    "print(len(d_standard_churned))\n",
    "print(len(d_standard_retained))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qb/krnv1mhn7h7b_hnb5z9d1dgw0000gn/T/ipykernel_97416/2939982177.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bln_standard = d_standard_churned.append(d_standard_retained_bis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2037\n",
      "2037\n"
     ]
    }
   ],
   "source": [
    "# The dataset is unbalanced. \n",
    "# With this code we will undersample the dataset and get balanced classes\n",
    "\n",
    "# index property contains the indexes of the d_retained dataset\n",
    "d_standard_retained_indexes = d_standard_retained.index\n",
    "\n",
    "# get as many fraud indexes (randomly) as non fraud occurrences\n",
    "np.random.seed(42)\n",
    "random_d_standard_retained_indexes = np.random.choice(d_standard_retained_indexes, len(d_standard_churned))\n",
    "\n",
    "# Keep those entries in d_retained\n",
    "d_standard_retained_bis = d_standard.loc[random_d_standard_retained_indexes]\n",
    "\n",
    "# We will form the balanced dataset concatenating d_retained and d_churned\n",
    "bln_standard = d_standard_churned.append(d_standard_retained_bis)\n",
    "\n",
    "# Check the result\n",
    "print(len(bln_standard[bln_standard.Exited == 1]))\n",
    "print(len(bln_standard[bln_standard.Exited == 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TRAIN AND TEST DATA SETS**\n",
    "\n",
    "At this point, what I have noticed is that we should sepparate the data set into a **TEST** dataframe and a **TRAIN** dataframe. So what I will do is sepparate the **'d'** dataframe (the initial dataframe) into test and train. Nevertheless I have noticed that some of the libraries do this step on their own. So this might be useful or not, +++++ I would have to balance these dataframes whenever necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "d_train = d.sample(frac=0.8,random_state=200)\n",
    "d_test = d.drop(d_train.index)\n",
    "print(len(d_train))\n",
    "print(len(d_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "d_standard_train = d_standard.sample(frac=0.8,random_state=200)\n",
    "d_standard_test = d_standard.drop(d_standard_train.index)\n",
    "print(len(d_standard_train))\n",
    "print(len(d_standard_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________________________________________________\n",
    "## **OUTPUT OF THE DATA PREPARATION SECTION**\n",
    "\n",
    "In this chunk of Markdown I give an overview and comments about the outputs of the ***DATA PREPARATION*** section of the exercise. \n",
    "\n",
    "This gives me a pretty good summary of the variables I can use in the next sections. \n",
    "\n",
    "### **Non-Standardised Outputs:**\n",
    "\n",
    "- **d** = original dataframe to which I performed the next operations:\n",
    "    - Removed NULL values (NaN)\n",
    "    - Narrowed down the columns, removing *RowNumber, CustomerID and Surname* columns\n",
    "    - Encoded the next category columns: *Geography and Gender*\n",
    "\n",
    "- **d_churned** = dataframe with the rows from **d** that have an exited value of 1 (this means customers that left) ***length = 2037***\n",
    "- **d_retained** = dataframe with the rows from **d** that have an exited value of 0 (this means customers that are loyal) ***length = 7963***\n",
    "- **d_retained_bis** = this is a narrowed down version of **d_retained** with the same number of rows , chosen randomly ***length = 2037***\n",
    "\n",
    "- **bln** = balanced data set with 2037 rows of churned customers and 2037 rows of retained customers ***length = 2 * 2037***\n",
    "\n",
    "- **d_train** = train data set, ***length = 8000***\n",
    "- **d_test** = test data set, ***length = 2000***\n",
    "\n",
    "\n",
    "### **Standardised Outputs:**\n",
    "I will first do the classification part of the exercise with the non-standardised data set and the with the standardised, this will enable be to compare the results. I decided not to compare the unbalanced and balanced results, assuming the balanced data set will produce much better predictions. \n",
    "\n",
    "- **d_standard** = STANDARDISED original dataframe to which I performed the next operations:\n",
    "    - Removed NULL values (NaN)\n",
    "    - Narrowed down the columns, removing *RowNumber, CustomerID and Surname* columns\n",
    "    - Encoded the next category columns: *Geography and Gender*\n",
    "\n",
    "- **d_standard_churned** = STANDARDISED dataframe with the rows from **d** that have an exited value of 1 (this means customers that left) ***length = 2037***\n",
    "- **d_standard_retained** = STANDARDISED dataframe with the rows from **d** that have an exited value of 0 (this means customers that are loyal) ***length = 7963***\n",
    "- **d_standard_retained_bis** = STANDARDISED this is a narrowed down version of **d_retained** with the same number of rows , chosen randomly ***length = 2037***\n",
    "\n",
    "- **bln_standard** = STANDARDISED balanced data set with 2037 rows of churned customers and 2037 rows of retained customers ***length = 2 * 2037***\n",
    "\n",
    "- **d_standard_train** = STANDARDISED train data set, ***length = 8000***\n",
    "- **d_standard_test** = STANDARDISED test data set, ***length = 2000***\n",
    "\n",
    "________________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________________________________________________\n",
    "# **CLASSIFICATION MODELS APPLICATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________________________________________________\n",
    "## **1. LogisticRegression**\n",
    "\n",
    "Logistic regression, despite its name, is a linear model for classification rather than regression. Logistic regression is also known in the literature as logit regression, maximum-entropy classification (MaxEnt) or the log-linear classifier. In this model, the probabilities describing the possible outcomes of a single trial are modeled using a logistic function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.1. LogisticRegression, Unbalanced, Non-standardised, with Train and Test dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: --------------------\n",
      "[[1552   58]\n",
      " [ 308   82]]\n",
      "Mean acccuracy: 0.817\n",
      "The cross_val_score function returns a vector with the score for every partition in the cross validation: \n",
      "[0.78091438 0.75933128 0.77008133 0.76541565 0.74144561]\n",
      "ROC Area Under the Curve: 0.7634376468616683\n"
     ]
    }
   ],
   "source": [
    "LogReg1 = LogisticRegression(random_state=0).fit(d_train.drop(columns = [\"Exited\"]),d_train[\"Exited\"])\n",
    "LogReg1_prediction = LogReg1.predict(d_test.drop(columns = [\"Exited\"]))\n",
    "auc11 = cross_val_score(LogisticRegression(random_state=0), d.drop(columns = [\"Exited\"]),d[\"Exited\"], scoring ='roc_auc')\n",
    "\n",
    "print (\"Confusion Matrix: --------------------\")\n",
    "print(metrics.confusion_matrix(d_test[\"Exited\"], LogReg1_prediction))\n",
    "print (\"Mean acccuracy: \" + str(LogReg1.score(d_test.drop(columns = [\"Exited\"]),d_test[\"Exited\"])))\n",
    "print(\"The cross_val_score function returns a vector with the score for every partition in the cross validation: \")\n",
    "print(auc11)\n",
    "print (\"ROC Area Under the Curve: \" + str(auc11.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy** = 0.817\n",
    "\n",
    "**AUC** = 0.7634"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.2. LogisticRegression, Unbalanced, Standardised, with Train and Test dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: --------------------\n",
      "[[1552   58]\n",
      " [ 308   82]]\n",
      "Mean acccuracy: 0.817\n",
      "The cross_val_score function returns a vector with the score for every partition in the cross validation: \n",
      "[0.78091438 0.75933128 0.77008133 0.76541565 0.74144561]\n",
      "ROC Area Under the Curve: 0.7634376468616683\n"
     ]
    }
   ],
   "source": [
    "LogReg2 = LogisticRegression(random_state=0).fit(d_standard_train.drop(columns = [\"Exited\"]),d_standard_train[\"Exited\"])\n",
    "LogReg2_prediction = LogReg2.predict(d_standard_test.drop(columns = [\"Exited\"]))\n",
    "auc12 = cross_val_score(LogisticRegression(random_state=0), d_standard.drop(columns = [\"Exited\"]),d_standard[\"Exited\"], scoring ='roc_auc')\n",
    "\n",
    "print (\"Confusion Matrix: --------------------\")\n",
    "print(metrics.confusion_matrix(d_standard_test[\"Exited\"], LogReg2_prediction))\n",
    "print (\"Mean acccuracy: \" + str(LogReg2.score(d_standard_test.drop(columns = [\"Exited\"]),d_standard_test[\"Exited\"])))\n",
    "print(\"The cross_val_score function returns a vector with the score for every partition in the cross validation: \")\n",
    "print(auc12)\n",
    "print (\"ROC Area Under the Curve: \" + str(auc12.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy** = 0.817\n",
    "\n",
    "**AUC** = 0.7634\n",
    "\n",
    "As we can see, with unbalanced datasets, the logistic regression model gives the same accuracy, so we can conclude that the standardisation does not make a difference. Let's try with the balanced set now: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.3. LogisticRegression, Balanced, Non-Standardised**\n",
    "\n",
    "First let's divide the balanced data set 'bln' into train and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3259\n",
      "737\n"
     ]
    }
   ],
   "source": [
    "bln_train = bln.sample(frac=0.8,random_state=200)\n",
    "bln_test = bln.drop(bln_train.index)\n",
    "print(len(bln_train))\n",
    "print(len(bln_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's implement the LogisticRegression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66748466 0.65521472 0.63558282 0.69079755 0.66584767]\n",
      "Mean accuracy: 0.6629854840897785\n",
      "Confusion Matrix: --------------------\n",
      "[[225  99]\n",
      " [134 279]]\n",
      "Mean acccuracy: 0.683853459972863\n",
      "The cross_val_score function returns a vector with the score for every partition in the cross validation: \n",
      "[0.71344004 0.69730091 0.70093222 0.74654333 0.72639135]\n",
      "Mean ROC Area Under the Curve: 0.7169215701662587\n"
     ]
    }
   ],
   "source": [
    "LogReg3 = LogisticRegression(random_state=0).fit(bln_train.drop(columns = [\"Exited\"]),bln_train[\"Exited\"])\n",
    "LogReg3_prediction = LogReg3.predict(bln_test.drop(columns = [\"Exited\"]))\n",
    "auc13 = cross_val_score(LogisticRegression(random_state=0), bln.drop(columns = [\"Exited\"]),bln[\"Exited\"], scoring ='roc_auc')\n",
    "#Here I'm trying to caculate the mean accuracy with the crass_val_score function -> different method but pretty much the same result\n",
    "auc131 = cross_val_score(LogisticRegression(random_state=0), bln.drop(columns = [\"Exited\"]),bln[\"Exited\"])\n",
    "print (auc131)\n",
    "print (\"Mean accuracy: \" + str(auc131.mean()))\n",
    "\n",
    "print (\"Confusion Matrix: --------------------\")\n",
    "print(metrics.confusion_matrix(bln_test[\"Exited\"], LogReg3_prediction))\n",
    "print (\"Mean acccuracy: \" + str(LogReg3.score(bln_test.drop(columns = [\"Exited\"]),bln_test[\"Exited\"])))\n",
    "print(\"The cross_val_score function returns a vector with the score for every partition in the cross validation: \")\n",
    "print(auc13)\n",
    "print (\"Mean ROC Area Under the Curve: \" + str(auc13.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy** = 0.68385\n",
    "\n",
    "**AUC** = 0.7169\n",
    "\n",
    "Here we obtain a curious result, the accuracy is lower that the AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.4. LogisticRegression, Balanced, Non-Standardised**\n",
    "\n",
    "First let's divide the balanced standarised data set 'bln_standard' into train and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3259\n",
      "737\n"
     ]
    }
   ],
   "source": [
    "bln_standard_train = bln_standard.sample(frac=0.8,random_state=200)\n",
    "bln_standard_test = bln_standard.drop(bln_standard_train.index)\n",
    "print(len(bln_standard_train))\n",
    "print(len(bln_standard_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72638037 0.71042945 0.71042945 0.7202454  0.69287469]\n",
      "Mean accuracy: 0.712071871090276\n",
      "Confusion Matrix: --------------------\n",
      "[[239  85]\n",
      " [122 291]]\n",
      "Mean acccuracy: 0.7191316146540027\n",
      "The cross_val_score function returns a vector with the score for every partition in the cross validation: \n",
      "[0.77301633 0.76182734 0.77114949 0.78870983 0.76834149]\n",
      "Mean ROC Area Under the Curve: 0.7726088969838065\n"
     ]
    }
   ],
   "source": [
    "LogReg4 = LogisticRegression(random_state=0).fit(bln_standard_train.drop(columns = [\"Exited\"]),bln_standard_train[\"Exited\"])\n",
    "LogReg4_prediction = LogReg4.predict(bln_standard_test.drop(columns = [\"Exited\"]))\n",
    "auc14 = cross_val_score(LogisticRegression(random_state=0), bln_standard.drop(columns = [\"Exited\"]),bln_standard[\"Exited\"], scoring ='roc_auc')\n",
    "#Here I'm trying to caculate the mean accuracy with the crass_val_score function -> different method but pretty much the same result\n",
    "auc141 = cross_val_score(LogisticRegression(random_state=0), bln_standard.drop(columns = [\"Exited\"]),bln_standard[\"Exited\"])\n",
    "print (auc141)\n",
    "print (\"Mean accuracy: \" + str(auc141.mean()))\n",
    "\n",
    "print (\"Confusion Matrix: --------------------\")\n",
    "print(metrics.confusion_matrix(bln_standard_test[\"Exited\"], LogReg4_prediction))\n",
    "print (\"Mean acccuracy: \" + str(LogReg4.score(bln_standard_test.drop(columns = [\"Exited\"]),bln_standard_test[\"Exited\"])))\n",
    "print(\"The cross_val_score function returns a vector with the score for every partition in the cross validation: \")\n",
    "print(auc14)\n",
    "print (\"Mean ROC Area Under the Curve: \" + str(auc14.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy** = 0.7191\n",
    "\n",
    "**AUC** = 0.7726\n",
    "\n",
    "With the balanced set, the standarisation improves accuracy, Nevertheless we obtain the same result of the AUC being lower that the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.5. Conclusions of LogisticRegression**\n",
    "\n",
    "The standarisation does not make a difference with the unbalanced set, and both the Accuracy and AUC are higher than with a balanced set. \n",
    "\n",
    "But using the balanced set, we observe a curious result, the AUC is higher than the accuracy. \n",
    "\n",
    "|                              | Accuracy | Roc_AUC |\n",
    "|------------------------------|----------|---------|\n",
    "| Unbalanced + Non-standardise | 0.817    | 0.7634  |\n",
    "| Unbalanced + Standardise     | 0.817    | 0.7634  |\n",
    "| Balanced + Non-standardise   | 0.6838   | 0.7169  |\n",
    "| Balanced + Standardise       | 0.7191   | 0.7726  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________________________________________________\n",
    "## **2. SupportVectorClassification (SVC)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we set up the GridSearchCV to tune the metaparameters. \n",
    "\n",
    "- **estimator:** SVC() support vecor classification\n",
    "\n",
    "- **parameter grid:** these are the parameters we have defined in the 'params' variable where: \n",
    "    - **C:** Regularization parameter. The strength of the regularization is inversely proportional to C. Must be strictly positive.\n",
    "    - **Kernel:** Specifies the kernel type to be used in the algorithm. In this case 'poly' which dived the dataset into 2 degrees with a split0_testScore of \t\n",
    "        0.80\n",
    "    - **degree:** Degree of the polynomial kernel function (‘poly’). Ignored by all other kernels.\n",
    "    \n",
    "\n",
    "- **scoring:** Strategy to evaluate the performance of the cross-validated model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________________________________________________\n",
    "### **GridSearchCV application to SupportVectorClassification:**\n",
    "Here I show the code needed to implement the GridSearchCV module, I do this to show you that I have used it. Nevertheless I have decided not to proceed with this module to study the SupportVectorClassification, because I have determined that I won't be able to produce as many results as using the SVC model directly, the cross_val_score function will already give me the partitions I want to do the cross validation. Same thing for the GradientBoostingClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this point you must include the code to train the models, tune their metaparameters and crossvalidate the results\n",
    "# An example of use of GridSearchCV with the roc_auc score:\n",
    "\n",
    "#   # define the parameters grid  \n",
    "params = [{'C': [1, 2], 'kernel': ['poly'], 'degree': [1, 2]}]\n",
    "\n",
    "#   # get the models calling GridSearchCV\n",
    "svc_models = GridSearchCV(SVC(), params, scoring='roc_auc')\n",
    "best_svc = svc_models.fit(d.drop(columns = [\"Exited\"]),d[\"Exited\"])\n",
    "svc = svc_models.score(d.drop(columns = [\"Exited\"]),d[\"Exited\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Best Score (roc_auc_score): 0.778\n",
      "   Best Parameters: \n",
      "     C: 1\n",
      "     degree: 2\n",
      "     kernel: poly\n"
     ]
    }
   ],
   "source": [
    "print('   Best Score (roc_auc_score): '+ str(np.round(best_svc.best_score_, 3)))\n",
    "\n",
    "print('   Best Parameters: ')\n",
    "\n",
    "for key, value in best_svc.best_params_.items():\n",
    "    print('     ' + str(key) + ': ' + str(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DISCLAIMER:** I have only done the case of Unbalanced not standarised data set with GridSearchCV because it has proven to give the most accurate results\n",
    "\n",
    "**AUC=** 0.778 -> Best AUC calculated using the GridSearchCV module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.1. SVC() Unbalanced, Non-standardised**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: --------------------\n",
      "[[1599   11]\n",
      " [ 318   72]]\n",
      "Mean accuracy: 0.82875\n",
      "The cross_val_score function returns a vector with the score for every partition in the cross validation: \n",
      "[0.8210384  0.82685486 0.83524048 0.82970644 0.8115203 ]\n",
      "ROC Area Under the Curve: 0.8248720975152548\n"
     ]
    }
   ],
   "source": [
    "svc1 = SVC(random_state=0).fit(d_train.drop(columns = [\"Exited\"]),d_train[\"Exited\"])\n",
    "scv1_prediction = svc1.predict(d_test.drop(columns = [\"Exited\"]))\n",
    "svc1_auc = cross_val_score(SVC(random_state=0), d.drop(columns = [\"Exited\"]),d[\"Exited\"], scoring ='roc_auc')\n",
    "\n",
    "print (\"Confusion Matrix: --------------------\")\n",
    "print(metrics.confusion_matrix(d_test[\"Exited\"], scv1_prediction))\n",
    "print(\"Mean accuracy: \" + str(svc1.score(d_train.drop(columns = [\"Exited\"]),d_train[\"Exited\"])))\n",
    "print(\"The cross_val_score function returns a vector with the score for every partition in the cross validation: \")\n",
    "print(svc1_auc)\n",
    "print (\"ROC Area Under the Curve: \" + str(svc1_auc.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy** = 0.82875\n",
    "\n",
    "**AUC** = 0.82487"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.2. SVC() Unbalanced, Standardised**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: --------------------\n",
      "[[1599   11]\n",
      " [ 318   72]]\n",
      "Mean accuracy: 0.82875\n",
      "The cross_val_score function returns a vector with the score for every partition in the cross validation: \n",
      "[0.8210384  0.82685486 0.83524048 0.82970644 0.8115203 ]\n",
      "ROC Area Under the Curve: 0.8248720975152548\n"
     ]
    }
   ],
   "source": [
    "svc2 = SVC(random_state=0).fit(d_standard_train.drop(columns = [\"Exited\"]),d_standard_train[\"Exited\"])\n",
    "scv2_prediction = svc2.predict(d_standard_test.drop(columns = [\"Exited\"]))\n",
    "svc2_auc = cross_val_score(SVC(random_state=0), d_standard.drop(columns = [\"Exited\"]),d_standard[\"Exited\"], scoring ='roc_auc')\n",
    "\n",
    "print (\"Confusion Matrix: --------------------\")\n",
    "print(metrics.confusion_matrix(d_standard_test[\"Exited\"], scv2_prediction))\n",
    "print(\"Mean accuracy: \" + str(svc2.score(d_standard_train.drop(columns = [\"Exited\"]),d_standard_train[\"Exited\"])))\n",
    "print(\"The cross_val_score function returns a vector with the score for every partition in the cross validation: \")\n",
    "print(svc2_auc)\n",
    "print (\"ROC Area Under the Curve: \" + str(svc2_auc.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy** = 0.82875\n",
    "\n",
    "**AUC** = 0.82487\n",
    "\n",
    "-> Once again, with the unbalanced data set, the standardisation does not make a difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.3. SVC() Balanced, Non-Standardised**\n",
    "First let's divide the balanced data set 'bln' into train and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3259\n",
      "737\n"
     ]
    }
   ],
   "source": [
    "bln_train = bln.sample(frac=0.8,random_state=200)\n",
    "bln_test = bln.drop(bln_train.index)\n",
    "print(len(bln_train))\n",
    "print(len(bln_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: --------------------\n",
      "[[131 193]\n",
      " [ 99 314]]\n",
      "Mean accuracy: 0.566738263270942\n",
      "The cross_val_score function returns a vector with the score for every partition in the cross validation: \n",
      "[0.5980633  0.56941032 0.56874789 0.59538951 0.57967147]\n",
      "ROC Area Under the Curve: 0.5822564993615723\n"
     ]
    }
   ],
   "source": [
    "svc3 = SVC(random_state=0).fit(bln_train.drop(columns = [\"Exited\"]),bln_train[\"Exited\"])\n",
    "scv3_prediction = svc3.predict(bln_test.drop(columns = [\"Exited\"]))\n",
    "svc3_auc = cross_val_score(SVC(random_state=0), bln.drop(columns = [\"Exited\"]),bln[\"Exited\"], scoring ='roc_auc')\n",
    "\n",
    "print (\"Confusion Matrix: --------------------\")\n",
    "print(metrics.confusion_matrix(bln_test[\"Exited\"], scv3_prediction))\n",
    "print(\"Mean accuracy: \" + str(svc3.score(bln_train.drop(columns = [\"Exited\"]),bln_train[\"Exited\"])))\n",
    "print(\"The cross_val_score function returns a vector with the score for every partition in the cross validation: \")\n",
    "print(svc3_auc)\n",
    "print (\"ROC Area Under the Curve: \" + str(svc3_auc.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy** = 0.56673\n",
    "\n",
    "**AUC** = 0.58225\n",
    "\n",
    "And once again, we see a huge drop in the accuracy with the balanced set. Let's try it standardising the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.4. SVC() Balanced,Standardised**\n",
    "First let's divide the balanced standarised data set 'bln_standard' into train and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3259\n",
      "737\n"
     ]
    }
   ],
   "source": [
    "bln_standard_train = bln_standard.sample(frac=0.8,random_state=200)\n",
    "bln_standard_test = bln_standard.drop(bln_standard_train.index)\n",
    "print(len(bln_standard_train))\n",
    "print(len(bln_standard_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: --------------------\n",
      "[[248  76]\n",
      " [104 309]]\n",
      "Mean accuracy: 0.7465480208652961\n",
      "The cross_val_score function returns a vector with the score for every partition in the cross validation: \n",
      "[0.8044214  0.79241942 0.80693862 0.82281881 0.80788293]\n",
      "ROC Area Under the Curve: 0.8068962378400159\n"
     ]
    }
   ],
   "source": [
    "svc4 = SVC(random_state=0).fit(bln_standard_train.drop(columns = [\"Exited\"]),bln_standard_train[\"Exited\"])\n",
    "scv4_prediction = svc4.predict(bln_standard_test.drop(columns = [\"Exited\"]))\n",
    "svc4_auc = cross_val_score(SVC(random_state=0), bln_standard.drop(columns = [\"Exited\"]),bln_standard[\"Exited\"], scoring ='roc_auc')\n",
    "\n",
    "print (\"Confusion Matrix: --------------------\")\n",
    "print(metrics.confusion_matrix(bln_standard_test[\"Exited\"], scv4_prediction))\n",
    "print(\"Mean accuracy: \" + str(svc4.score(bln_standard_train.drop(columns = [\"Exited\"]),bln_standard_train[\"Exited\"])))\n",
    "print(\"The cross_val_score function returns a vector with the score for every partition in the cross validation: \")\n",
    "print(svc4_auc)\n",
    "print (\"ROC Area Under the Curve: \" + str(svc4_auc.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy** = 0.7465\n",
    "\n",
    "**AUC** = 0.80689\n",
    "\n",
    "With the balanced set we see again a raise in the accuracy wheneever we standardise the data, but still the auc is higher than the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.5. Conclusions of SupportVectorClassification**\n",
    "\n",
    "The standarisation does not make a difference with the unbalanced set, and both the Accuracy and AUC are higher than with a balanced set. \n",
    "\n",
    "But using the balanced set, we observe a curious result, the AUC is higher than the accuracy. \n",
    "\n",
    "|                              | Accuracy | Roc_AUC |\n",
    "|------------------------------|----------|---------|\n",
    "| Unbalanced + Non-standardise | 0.82875  | 0.82487 |\n",
    "| Unbalanced + Standardise     | 0.82875  | 0.82487 |\n",
    "| Balanced + Non-standardise   | 0.56673  | 0.58225 |\n",
    "| Balanced + Standardise       | 0.7465   | 0.80689 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________________________________________________\n",
    "## **3. GradientBoostClassifier**\n",
    "This method uses the gradients in the loss function to weight the points that are difficult to predict. Ensemble methods are very powerful and usually get very good results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **GridSearchCV application to SupportVectorClassification:**\n",
    "Here I show the code needed to implement the GridSearchCV module, I do this to show you that I have used it. Nevertheless I have decided not to proceed with this module to study the SupportVectorClassification, because I have determined that I won't be able to produce as many results as using the SVC model directly, the cross_val_score function will already give me the partitions I want to do the cross validation. Same thing for the GradientBoostingClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this point you must include the code to train the models, tune their metaparameters and crossvalidate the results\n",
    "# An example of use of GridSearchCV with the roc_auc score:\n",
    "\n",
    "#   # define the parameters grid  \n",
    "params = [{'learning_rate': [0.001, 0.01], 'n_estimators': [600], 'criterion': ['friedman_mse', 'squared_error']}]\n",
    "\n",
    "#   # get the models calling GridSearchCV\n",
    "gbc_models = GridSearchCV(GradientBoostingClassifier(random_state=0), params, scoring='roc_auc')\n",
    "best_gbc = gbc_models.fit(d.drop(columns = [\"Exited\"]),d[\"Exited\"])\n",
    "gbc = gbc_models.score(d.drop(columns = [\"Exited\"]),d[\"Exited\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Best Score (roc_auc_score): 0.863\n",
      "   Best Parameters: \n",
      "     criterion: friedman_mse\n",
      "     learning_rate: 0.01\n",
      "     n_estimators: 600\n"
     ]
    }
   ],
   "source": [
    "print('   Best Score (roc_auc_score): '+ str(np.round(best_gbc.best_score_, 3)))\n",
    "\n",
    "print('   Best Parameters: ')\n",
    "\n",
    "for key, value in best_gbc.best_params_.items():\n",
    "    print('     ' + str(key) + ': ' + str(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DISCLAIMER:** I have only done the case of Unbalanced not standarised data set with GridSearchCV because it has proven to give the most accurate results\n",
    "\n",
    "**AUC=** 0.863 -> Best AUC calculated using the GridSearchCV module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.1. GBC Unbalanced, Non-standarised**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: --------------------\n",
      "[[1551   59]\n",
      " [ 208  182]]\n",
      "Mean accuracy: 0.87325\n",
      "The cross_val_score function returns a vector with the score for every partition in the cross validation: \n",
      "[0.8655879  0.86832677 0.86441526 0.86673191 0.86191045]\n",
      "ROC Area Under the Curve: 0.8653944579755087\n"
     ]
    }
   ],
   "source": [
    "gbc1 = GradientBoostingClassifier(random_state=0).fit(d_train.drop(columns = [\"Exited\"]),d_train[\"Exited\"])\n",
    "gbc1_prediction = gbc1.predict(d_test.drop(columns = [\"Exited\"]))\n",
    "gbc1_auc = cross_val_score(GradientBoostingClassifier(random_state=0), d.drop(columns = [\"Exited\"]),d[\"Exited\"], scoring ='roc_auc')\n",
    "\n",
    "print (\"Confusion Matrix: --------------------\")\n",
    "print(metrics.confusion_matrix(d_test[\"Exited\"], gbc1_prediction))\n",
    "print(\"Mean accuracy: \" + str(gbc1.score(d_train.drop(columns = [\"Exited\"]),d_train[\"Exited\"])))\n",
    "print(\"The cross_val_score function returns a vector with the score for every partition in the cross validation: \")\n",
    "print(gbc1_auc)\n",
    "print (\"ROC Area Under the Curve: \" + str(gbc1_auc.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy** = 0.87325\n",
    "\n",
    "**AUC** = 0.8653"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.2. GBC Unbalanced, Standarised**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: --------------------\n",
      "[[1551   59]\n",
      " [ 208  182]]\n",
      "Mean accuracy: 0.87325\n",
      "The cross_val_score function returns a vector with the score for every partition in the cross validation: \n",
      "[0.8655879  0.86832677 0.86441526 0.86673191 0.86191045]\n",
      "ROC Area Under the Curve: 0.8653944579755087\n"
     ]
    }
   ],
   "source": [
    "gbc2 = GradientBoostingClassifier(random_state=0).fit(d_standard_train.drop(columns = [\"Exited\"]),d_standard_train[\"Exited\"])\n",
    "gbc2_prediction = gbc2.predict(d_standard_test.drop(columns = [\"Exited\"]))\n",
    "gbc2_auc = cross_val_score(GradientBoostingClassifier(random_state=0), d_standard.drop(columns = [\"Exited\"]),d_standard[\"Exited\"], scoring ='roc_auc')\n",
    "\n",
    "print (\"Confusion Matrix: --------------------\")\n",
    "print(metrics.confusion_matrix(d_standard_test[\"Exited\"], gbc2_prediction))\n",
    "print(\"Mean accuracy: \" + str(gbc2.score(d_standard_train.drop(columns = [\"Exited\"]),d_standard_train[\"Exited\"])))\n",
    "print(\"The cross_val_score function returns a vector with the score for every partition in the cross validation: \")\n",
    "print(gbc2_auc)\n",
    "print (\"ROC Area Under the Curve: \" + str(gbc2_auc.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy** = 0.87325\n",
    "\n",
    "**AUC** = 0.8653\n",
    "\n",
    "Once again same result for the unbalanced data set either standarised or non-standardised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.3. GBC Balanced, Non-standarised**\n",
    "First let's divide the balanced data set 'bln' into train and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3259\n",
      "737\n"
     ]
    }
   ],
   "source": [
    "bln_train = bln.sample(frac=0.8,random_state=200)\n",
    "bln_test = bln.drop(bln_train.index)\n",
    "print(len(bln_train))\n",
    "print(len(bln_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: --------------------\n",
      "[[255  69]\n",
      " [ 99 314]]\n",
      "Mean accuracy: 0.8158944461491255\n",
      "The cross_val_score function returns a vector with the score for every partition in the cross validation: \n",
      "[0.86530448 0.85562702 0.86256444 0.87204317 0.87198232]\n",
      "ROC Area Under the Curve: 0.8655042838631507\n"
     ]
    }
   ],
   "source": [
    "gbc3 = GradientBoostingClassifier(random_state=0).fit(bln_train.drop(columns = [\"Exited\"]),bln_train[\"Exited\"])\n",
    "gbc3_prediction = gbc3.predict(bln_test.drop(columns = [\"Exited\"]))\n",
    "gbc3_auc = cross_val_score(GradientBoostingClassifier(random_state=0), bln.drop(columns = [\"Exited\"]),bln[\"Exited\"], scoring ='roc_auc')\n",
    "\n",
    "print (\"Confusion Matrix: --------------------\")\n",
    "print(metrics.confusion_matrix(bln_test[\"Exited\"], gbc3_prediction))\n",
    "print(\"Mean accuracy: \" + str(gbc3.score(bln_train.drop(columns = [\"Exited\"]),bln_train[\"Exited\"])))\n",
    "print(\"The cross_val_score function returns a vector with the score for every partition in the cross validation: \")\n",
    "print(gbc3_auc)\n",
    "print (\"ROC Area Under the Curve: \" + str(gbc3_auc.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy** = 0.8158\n",
    "\n",
    "**AUC** = 0.8655"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.4. GBC Balanced, Standarised**\n",
    "First let's divide the balanced standarised data set 'bln_standard' into train and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3259\n",
      "737\n"
     ]
    }
   ],
   "source": [
    "bln_standard_train = bln_standard.sample(frac=0.8,random_state=200)\n",
    "bln_standard_test = bln_standard.drop(bln_standard_train.index)\n",
    "print(len(bln_standard_train))\n",
    "print(len(bln_standard_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: --------------------\n",
      "[[255  69]\n",
      " [ 99 314]]\n",
      "Mean accuracy: 0.8158944461491255\n",
      "The cross_val_score function returns a vector with the score for every partition in the cross validation: \n",
      "[0.86551525 0.85562702 0.86256444 0.87204317 0.87206684]\n",
      "ROC Area Under the Curve: 0.8655633415280762\n"
     ]
    }
   ],
   "source": [
    "gbc4 = GradientBoostingClassifier(random_state=0).fit(bln_standard_train.drop(columns = [\"Exited\"]),bln_standard_train[\"Exited\"])\n",
    "gbc4_prediction = gbc4.predict(bln_standard_test.drop(columns = [\"Exited\"]))\n",
    "gbc4_auc = cross_val_score(GradientBoostingClassifier(random_state=0), bln_standard.drop(columns = [\"Exited\"]),bln_standard[\"Exited\"], scoring ='roc_auc')\n",
    "\n",
    "print (\"Confusion Matrix: --------------------\")\n",
    "print(metrics.confusion_matrix(bln_standard_test[\"Exited\"], gbc4_prediction))\n",
    "print(\"Mean accuracy: \" + str(gbc4.score(bln_standard_train.drop(columns = [\"Exited\"]),bln_standard_train[\"Exited\"])))\n",
    "print(\"The cross_val_score function returns a vector with the score for every partition in the cross validation: \")\n",
    "print(gbc4_auc)\n",
    "print (\"ROC Area Under the Curve: \" + str(gbc4_auc.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy** = 0.8158\n",
    "\n",
    "**AUC** = 0.8655"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.5. Conclusions of GradientBoostClassifier**\n",
    "\n",
    "The standarisation does not make a difference with the unbalanced set, and both the Accuracy and AUC are higher than with a balanced set. \n",
    "\n",
    "But using the balanced set, we observe a curious result, the AUC is higher than the accuracy. \n",
    "\n",
    "|                              | Accuracy | Roc_AUC |\n",
    "|------------------------------|----------|---------|\n",
    "| Unbalanced + Non-standardise | 0.87325  | 0.86539 |\n",
    "| Unbalanced + Standardise     | 0.87325  | 0.86539 |\n",
    "| Balanced + Non-standardise   | 0.8158   | 0.8655  |\n",
    "| Balanced + Standardise       | 0.8158   | 0.8655  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________________________________________________________________________________________________________________________________________\n",
    "# **COMPARISON BETWEEN THE MODELS**\n",
    "__________________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next tables have been calculated through the implementation of the code for each of the models. Calculation the confusion matrix, mean accuracy and roc_acu for each of the cases. The cases include all combinations for the data set between Balanced and Unbalanced, and Standarised and Non-standarised."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Logistic Regression**\n",
    " LogisticRegression            | Accuracy | Roc_AUC |\n",
    "|------------------------------|----------|---------|\n",
    "| Unbalanced + Non-standardise | 0.817    | 0.7634  |\n",
    "| Unbalanced + Standardise     | 0.817    | 0.7634  |\n",
    "| Balanced + Non-standardise   | 0.6838   | 0.7169  |\n",
    "| Balanced + Standardise       | 0.7191   | 0.7726  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **SUPPORT VECTOR CLASSIFICATION**\n",
    "| SupportVectorClassification  | Accuracy | Roc_AUC |\n",
    "|------------------------------|----------|---------|\n",
    "| Unbalanced + Non-standardise | 0.82875  | 0.82487 |\n",
    "| Unbalanced + Standardise     | 0.82875  | 0.82487 |\n",
    "| Balanced + Non-standardise   | 0.56673  | 0.58225 |\n",
    "| Balanced + Standardise       | 0.7465   | 0.80689 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **GRADIENT BOOST CLASSIFIER**\n",
    "| GradientBoostClassifier      | Accuracy | Roc_AUC |\n",
    "|------------------------------|----------|---------|\n",
    "| Unbalanced + Non-standardise | 0.87325  | 0.86539 |\n",
    "| Unbalanced + Standardise     | 0.87325  | 0.86539 |\n",
    "| Balanced + Non-standardise   | 0.8158   | 0.8655  |\n",
    "| Balanced + Standardise       | 0.8158   | 0.8655  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a close examination of each of the cases and models, the best model to predict the if a customer will leave the ccompany is the GradientBoostClassifier. For wich I obtained better results for the Unbalanced + Standardise data set with an AUC of 0.86529 and an accuracy of 0.8732. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "dc3f44e010abd26ab046284901ce9509711ac3cc1e8fdd0965c6a2a3e20ab15a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
